{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Image segmentation â€“ Basics**\n",
    "\n",
    "<div style=\"color:#777777;margin-top: -15px;\">\n",
    "<b>Author</b>: Norman Juchler |\n",
    "<b>Course</b>: MSLS CO4 |\n",
    "<b>Version</b>: v1.2 <br><br>\n",
    "<!-- Date: 16.04.2025 -->\n",
    "<!-- Comments: Text refactored -->\n",
    "</div>\n",
    "\n",
    "In this notebook on segmentation, we will explore different approaches to segment hematological images. As a first step, we will attempt to segment the cells using simple thresholding techniques.\n",
    "\n",
    "Several of the concepts discussed here are also covered in this insightful tutorial for the ImageJ/Fiji plugin [MorphoLibJ](https://imagej.net/plugins/morpholibj), which you may find helpful for further reference.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Preparations**\n",
    "\n",
    "Let's begin with the usual preparatory steps..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "import PIL\n",
    "from pathlib import Path\n",
    "\n",
    "# Jupyter / IPython configuration:\n",
    "# Automatically reload modules when modified\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Enable vectorized output (for nicer plots)\n",
    "%config InlineBackend.figure_formats = [\"svg\"]\n",
    "\n",
    "#Â Inline backend configuration\n",
    "%matplotlib inline\n",
    "\n",
    "# Enable this line if you want to use the interactive widgets\n",
    "# It requires the ipympl package to be installed.\n",
    "#%matplotlib widget\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"../\")\n",
    "import tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the same images that were used in the previous notebook on preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "img1 = cv.imread(\"../data/images/hematology-baso1.jpg\", cv.IMREAD_COLOR)\n",
    "img2 = cv.imread(\"../data/images/hematology-baso2.jpg\", cv.IMREAD_COLOR)\n",
    "img3 = cv.imread(\"../data/images/hematology-blast1.jpg\", cv.IMREAD_COLOR)\n",
    "\n",
    "img1 = cv.cvtColor(img1, cv.COLOR_BGR2RGB)\n",
    "img2 = cv.cvtColor(img2, cv.COLOR_BGR2RGB)\n",
    "img3 = cv.cvtColor(img3, cv.COLOR_BGR2RGB)\n",
    "\n",
    "tools.show_image_chain([img1, img2, img3], titles=[\"img1\", \"img2\", \"img3\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Method 1: Thresholding**\n",
    "\n",
    "We can segment images using basic thresholding techniques. In this example, we explore several thresholding methods available in OpenCV:\n",
    "\n",
    "- **Simple thresholding**: Use [`cv.threshold()`](https://docs.opencv.org/4.x/d7/d1b/group__imgproc__misc.html#gae8a4a146d1ca78c626a53577199e9c57)  \n",
    "  (with flags `cv.THRESH_BINARY` or `cv.THRESH_BINARY_INV`)\n",
    "- **Adaptive thresholding**: Use [`cv.adaptiveThreshold()`](https://docs.opencv.org/4.x/d7/d1b/group__imgproc__misc.html#ga72b913f352e4a1b1b397736707afcde3)\n",
    "- **Otsu's thresholding** : Use [`cv.threshold()`](https://docs.opencv.org/4.x/d7/d1b/group__imgproc__misc.html#gae8a4a146d1ca78c626a53577199e9c57)  \n",
    "  (with flags `cv.THRESH_BINARY + cv.THRESH_OTSU`)\n",
    "\n",
    "Thresholding segments pixels into foreground and background based on their intensity values, making it a form of *binary* segmentation*. The algorithm compares pixel intensities to a threshold value: Pixel values larger than the threshold are classified as *foreground*, pixels smaller or equal than the threshold are *background*.\n",
    "\n",
    "The threshold can be manually defined or automatically determined (e.g., by Otsuâ€™s method).\n",
    "\n",
    "As preparation, please review the following OpenCV documentation on thresholding methods:  \n",
    "[https://docs.opencv.org/4.x/d7/d4d/tutorial_py_thresholding.html](https://docs.opencv.org/4.x/d7/d4d/tutorial_py_thresholding.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "###    EXCERISE    ###\n",
    "######################\n",
    "\n",
    "# Choose here the image to work with\n",
    "img = img1\n",
    "\n",
    "# 1) Summarize the three different thresholding techniques in own words. Which methods\n",
    "#    use a global threshold, which ones apply a local threshold? \n",
    "\n",
    "# 2) Develop a strategy to segment the white blood cells (purple), the red blood cells \n",
    "# (red) and the background (white/gray). You may want to exploit the fact that we have\n",
    "# colors to work with:\n",
    "tools.show_image_chain([img[:,:,0], img[:,:,1], img[:,:,2]], titles=[\"R\", \"G\", \"B\"])\n",
    "\n",
    "# 3) Identify the different regions using thresholding\n",
    "mask_wbc = ...\n",
    "mask_rbc = ...\n",
    "mask_bg = ...\n",
    "\n",
    "# 4) Visualize the masks. Idea: combine the three masks into an RGB image\n",
    "mask_seg = ...\n",
    "\n",
    "# 5) Discuss your results. What could be improved? What are the limitations of this \n",
    "#    approach? Are the masks mutually exclusive? Are they accurate?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "## **Method 2: Color clustering**\n",
    "\n",
    "Instead of segmenting the image into foreground and background, we can attempt to classify different regions based on color similarity. A common approach for this is the [K-means clustering](https://en.wikipedia.org/wiki/K-means_clustering) algorithm. K-means classifies pixels into a predefined number of clusters based on their color values. Similarity is typically measured using a (Euclidean or non-Euclidean) distance between pixel values. The algorithm operates iteratively:\n",
    "\n",
    "1. Assign each pixel to the nearest cluster center.\n",
    "2. Update each cluster center as the mean of the pixels assigned to it.\n",
    "3. Repeat until the cluster centers converge.\n",
    "\n",
    "Here is a helpful [visualization](https://www.naftaliharris.com/blog/visualizing-k-means-clustering/) of how K-means clustering works.\n",
    "\n",
    "\n",
    "**Preparation:** Before you begin, check out these two tutorials:\n",
    "- Jason Brownlee (Machine Learning Mastery) on [color quantization with K-means](https://machinelearningmastery.com/k-means-clustering-in-opencv-and-application-for-color-quantization/)\n",
    "- Shubhang Agrawal on [image segmentation using K-means clustering](https://medium.com/swlh/image-segmentation-using-k-means-clustering-46a60488ae71). (The tutorial has a few flaws, please excuse). \n",
    "\n",
    "\n",
    "<!-- \n",
    "Resources:\n",
    "# Nice way of depicting the bars\n",
    "https://pyimagesearch.com/2014/05/26/opencv-python-k-means-color-clustering/\n",
    "# OpenCV\n",
    "https://docs.opencv.org/3.4/d1/d5c/tutorial_py_kmeans_opencv.html\n",
    "# Machine Learning Mastery\n",
    "https://machinelearningmastery.com/k-means-clustering-in-opencv-and-application-for-color-quantization/\n",
    "# Watershed\n",
    "https://docs.opencv.org/4.x/d3/db4/tutorial_py_watershed.html\n",
    "# Segmentation with Skimage \n",
    "https://github.com/ipython-books/cookbook-2nd-code/blob/master/chapter11_image/03_segmentation.ipynb\n",
    "# Combination between thresholding and color clustering\n",
    "https://towardsdatascience.com/image-color-segmentation-by-k-means-clustering-algorithm-5792e563f26e\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "###    EXCERISE    ###\n",
    "######################\n",
    "\n",
    "# Choose here the image to work with\n",
    "img = img1\n",
    "\n",
    "# 1) Reshape the color pixels into a Mx3 matrix (M: number of pixels)\n",
    "#    and convert the data type to float32.\n",
    "data = img.reshape(-1, 3).astype(np.float32)\n",
    "\n",
    "# 2) Apply the K-means algorithm to the data. Use the cv.kmeans function.\n",
    "#    Choose the number of clusters K=3.\n",
    "criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "K = 3\n",
    "ret, label, centers = cv.kmeans(data, K, None, criteria, 10, cv.KMEANS_RANDOM_CENTERS)\n",
    "# label contains the cluster index for each pixel\n",
    "# centers contains the cluster centers (colors!)\n",
    "\n",
    "# 3) Reshape and convert the data back to uint8\n",
    "img_seg = ...\n",
    "\n",
    "# 4) Visualize the segmented image\n",
    "tools.show_image_pair(img, img_seg, title1=\"Original\", title2=\"Segmented\");\n",
    "\n",
    "# 5) Repeat the process for a different color space (e.g. HSV)\n",
    "#    Is the clustering more robust? Why? When does this approach fail?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Method 3: Watershed algorithm for segmentation**\n",
    "\n",
    "The watershed algorithm is a powerful tool for image segmentation, particularly useful for separating complex or overlapping structures. It is based on the concept of watershed lines, which define boundaries between different regions in an image. The algorithm works by conceptually \"flooding\" the image from predefined seed points. As water spreads from each seed region, it continues flowing until it meets water from a neighboring region.  \n",
    "The boundaries where the regions meet are defined as the watershed lines, effectively separating the regions. Watershed segmentation can be applied based on pixel intensity or color and is especially effective for images with intricate shapes and touching objects.\n",
    "\n",
    "Our dataset has structural similarities to the image used in this [OpenCV watershed tutorial](https://docs.opencv.org/4.x/d3/db4/tutorial_py_watershed.html). We will now follow a simplified version of the tutorial to segment our images using the watershed method. The tutorial uses the following strategy:\n",
    "\n",
    "### **Overview / Steps**\n",
    "\n",
    "1. Convert the image to a binary mask using thresholding.\n",
    "2. Apply morphological operations to reduce noise and help separate objects. These operations are also used to identify regions that likely represent the background.\n",
    "3. Identify seed points for the watershed algorithm:\n",
    "   - Apply the distance transform to the binary mask. This computes, for each pixel, the distance to the nearest background pixel (value 0).\n",
    "   - Threshold the distance-transformed image to isolate blobs near the centers of objects of interest.\n",
    "   - Use the connected components algorithm to label and enumerate the seed regions, creating a labeled mask.\n",
    "   - Mark the background seed region (identified in step 2) with label `0`.\n",
    "4. Apply the watershed algorithm to segment the regions.\n",
    "5. Visualize the resulting segmentation.\n",
    "\n",
    "\n",
    "\n",
    "### **Note: Morphological operations**\n",
    "\n",
    "Morphological operations are a set of operations used to analyze and manipulate the shape of objects in an image. Although they are defined for various image types, they are most commonly applied to binary images. These operations involve a structuring element (kernel) that probes the image and modifies pixel values based on the interaction between the kernel and the image. The most common operations include dilation (expands shapes), erosion (shrinks shapes), opening (erosion followed by dilation), and closing (dilation followed by erosion). Morphological operations are useful for removing noise, separating objects, and connecting disjoint regions in an image. There is a separate notebook on morphological operations.\n",
    "\n",
    "**Further reading**:  \n",
    "- OpenCV documentation: [Link](https://docs.opencv.org/4.x/d9/d61/tutorial_py_morphological_ops.html)  \n",
    "- Beautiful illustration of morphological operations: [Link](https://penny-xu.github.io/blog/mathematical-morphology)  \n",
    "- Wikipedia article on mathematical morphology: [Link](https://en.wikipedia.org/wiki/Mathematical_morphology)  \n",
    "- Blog post on morphological operations: [Link](https://towardsdatascience.com/7bcf1ed11756)\n",
    "\n",
    "### **Note: Distance transform**\n",
    "The distance transform is useful for various image processing tasks. It computes the distance from each pixel to the nearest boundary (i.e., the closest background pixel) in a binary image. Distance transforms are used for operations like skeletonization, shape analysis, and segmentation. The algorithm propagates distance values from boundary pixels inward, typically using a metric such as the Euclidean distance. It is computationally efficient and widely available in image processing libraries.\n",
    "\n",
    "**Further reading**:  \n",
    "- Application of distance transform with watershed: [Link](https://docs.opencv.org/3.4/d2/dbd/tutorial_distance_transform.html)\n",
    "\n",
    "### **Note: Connected components**\n",
    "\n",
    "Connected components are regions in a binary image where pixels are connected based on predefined neighborhood rules (e.g., 4-connectivity or 8-connectivity). This technique is used to identify individual objects in a segmentation mask. The algorithm labels each connected region with a unique integer value, allowing for further analysis such as counting or measuring properties of each component.\n",
    "\n",
    "**Further reading**:  \n",
    "- Wikipedia article on connected component labeling: [Link](https://en.wikipedia.org/wiki/Connected-component_labeling)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "###    EXCERISE    ###\n",
    "######################\n",
    "\n",
    "img = img1\n",
    "\n",
    "# Implement the approach lined out above. You can copy paste the code \n",
    "# from the above link and plug our image into it. Try to understand the\n",
    "# code and the different steps. You may have to adjust the parameters\n",
    "# to get a good segmentation result.\n",
    "\n",
    "# https://docs.opencv.org/4.x/d3/db4/tutorial_py_watershed.html\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **AI driven segmentation**\n",
    "Deep learning is increasingly used for image segmentation tasks, with the U-Net architecture still being one of the most popular choices. U-Net is a convolutional neural network specifically designed for biomedical image segmentation. \n",
    "\n",
    "A specialized U-Net-based tool for medical imaging is [nnU-Net](https://github.com/MIC-DKFZ/nnUNet). It features self-configuring preprocessing and postprocessing, allowing the network to automatically adapt to the characteristics of the input data. nnU-Net is available as a Python package and can be installed via pip.\n",
    "\n",
    "Although machine learning and AI are not the core focus of this course, pre-trained models can still be applied to perform segmentation effectively. Unlike classical methods, deep learning models can learn features directly from the data and often generalize better to unseen examples. However, they require large labeled datasets for training, are more computationally demanding, and are often seen as \"black boxes\" â€“Â making it difficult to interpret their decisions.\n",
    "\n",
    "\n",
    "```python\n",
    "######################\n",
    "###    EXCERISE    ###\n",
    "######################\n",
    "```\n",
    "\n",
    "Visit the following resources and explore whether they could be useful for your own segmentation project:\n",
    "\n",
    "- **Segment Anything** by Meta AI [Demo](https://segment-anything.com/demo), [Paper](https://arxiv.org/abs/2304.02643), [Code](https://github.com/facebookresearch/segment-anything) \n",
    "- **Huggingface**: Collection of public pre-trained models. [Link](https://huggingface.co/models).\n",
    "  - Many models include a demo interface\n",
    "  - Background removal with [RemBG](https://huggingface.co/spaces/KenjieDec/RemBG)\n",
    "  - Another popular segmentation tool is [YOLO](https://huggingface.co/spaces/fcakyon/yolov8-segmentation) ([Code](https://huggingface.co/spaces/fcakyon/yolov8-segmentation))\n",
    "  - To search the entire Huggingface database for models: [Link](https://huggingface.co/models)\n",
    "- **TotalSegmentator** for anatomical CT (and MR) segmentation. [Demo](https://totalsegmentator.com/), [Paper](https://arxiv.org/abs/2208.05868), [Code](https://github.com/wasserth/TotalSegmentator)\n",
    "\n",
    "\n",
    "We have now explored several approaches to image segmentation.  How well you can apply them will depend on your specific problem â€“ and a bit of engineering skill. ðŸ˜Š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "###    EXERCISE    ###\n",
    "######################\n",
    "\n",
    "# Try using one of the models listed above to segment the cells in the image."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-msls-co4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
