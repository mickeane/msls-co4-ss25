{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Preprocessing**\n",
    "\n",
    "<div style=\"color:#777777;margin-top: -15px;\">\n",
    "<b>Author</b>: Norman Juchler |\n",
    "<b>Course</b>: MSLS CO4 |\n",
    "<b>Version</b>: v1.1 <br><br>\n",
    "<!-- Date: 05.03.2025 -->\n",
    "<!-- Comments: ... -->\n",
    "</div>\n",
    "\n",
    "Image preprocessing is a crucial step in medical image analysis, involving techniques such as resizing, cropping (region of interest selection), denoising, and intensity or color adjustments. The goal is to enhance image quality and optimize it for further processing, such as segmentation or classification. In this tutorial, we will use the OpenCV library to apply some of these preprocessing techniques.\n",
    "\n",
    "We will work with hematological images displaying red and white blood cells from a blood smear. In these images, red blood cells appear red and white blood cells are blue/purple. The background is white/gray. We will leverage color channel information to segment different cell types in later steps.\n",
    "\n",
    "![Hematology data](../data/images/hematology-collage.svg?9)\n",
    "\n",
    "This dataset presents several imperfections that can affect image quality and analysis: Low resolution limits details in cell structures; noise introduces unwanted pixel intensity variations; compression artifacts causes blockiness due to JPEG compression; and cell overlap makes segmentation more challenging, as blood cells often touch or obscure each other.\n",
    "\n",
    "To address these challenges and improve image quality, we will apply the following techniques:\n",
    "- **Cropping**: Select a region of interest (ROI)\n",
    "- **Resizing**: Standardize image dimensions\n",
    "- **Masking**: Isolate specific areas\n",
    "- **Denoising**: Reduce image noise\n",
    "- **Enhancing contrast**: Improve visibility of features\n",
    "- **Sharpening**: Highlight edges and fine details\n",
    "- **(Artifact removal**: Mitigate compression effects)\n",
    "- **Color conversion**: Convert images between color spaces (e.g., RGB to grayscale)\n",
    "- **Color correction / white balancing**: Correct color imbalances\n",
    "- **Background removal**: Eliminate unwanted background elements\n",
    "\n",
    "### **Further reading**: \n",
    "\n",
    "For a deeper understanding of image preprocessing, check out:\n",
    "- Geeks for Geeks: Image Enhancement Techniques using OpenCV. [Link](https://www.geeksforgeeks.org/image-enhancement-techniques-using-opencv-python/)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Preparations**\n",
    "\n",
    "Let's begin with some preparatory steps..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Jupyter / IPython configuration:\n",
    "# Automatically reload modules when modified\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Enable vectorized output (for nicer plots)\n",
    "%config InlineBackend.figure_formats = [\"svg\"]\n",
    "\n",
    "# Inline backend configuration\n",
    "%matplotlib inline\n",
    "\n",
    "# Enable this line if you want to use the interactive widgets\n",
    "# It requires the ipympl package to be installed.\n",
    "#%matplotlib widget\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"../\")\n",
    "import tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "img1 = cv.imread(\"../data/images/hematology-baso1.jpg\", cv.IMREAD_COLOR)\n",
    "img2 = cv.imread(\"../data/images/hematology-baso2.jpg\", cv.IMREAD_COLOR)\n",
    "img3 = cv.imread(\"../data/images/hematology-blast1.jpg\", cv.IMREAD_COLOR)\n",
    "\n",
    "plt.imshow(img1)\n",
    "plt.axis(\"off\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** OpenCV uses the BGR color space by default, while Matplotlib uses RGB. To ensure consistency, we convert images to RGB before displaying them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv.cvtColor(img1, cv.COLOR_BGR2RGB)\n",
    "img2 = cv.cvtColor(img2, cv.COLOR_BGR2RGB)\n",
    "img3 = cv.cvtColor(img3, cv.COLOR_BGR2RGB)\n",
    "\n",
    "images = [img1, img2, img3]\n",
    "\n",
    "# Let's display the images\n",
    "plt.imshow(img1)\n",
    "plt.axis(\"off\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following sections, we will use various functions to display images. Before proceeding, here is a brief overview of the available options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plain matplotlib\n",
    "plt.imshow(img1)\n",
    "plt.axis(\"off\");   # Hide axes.\n",
    "\n",
    "# Based on Jupyter's display() function.\n",
    "tools.display_image(img1)\n",
    "\n",
    "# Show pairs of images\n",
    "tools.show_image_pair(img1, img2, title1=\"Baso 1\", title2=\"Baso 2\")\n",
    "\n",
    "# Show axes coordinates\n",
    "tools.show_image_pair(img1, img2, title1=\"Baso 1\", title2=\"Baso 2\", show_axes=True)\n",
    "\n",
    "# Show a chain of images\n",
    "tools.show_image_chain([img1, img2, img3], titles=[\"Baso 1\", \"Baso 2\", \"Blast 1\"])\n",
    "\n",
    "# Show a grid of images\n",
    "images_tmp = images*2\n",
    "titles = [\"Baso 1\", \"Baso 2\", \"Blast 1\"]\n",
    "titles *= 2\n",
    "tools.show_image_grid(images_tmp, titles=titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Cropping**\n",
    "\n",
    "Cropping an image involves selecting a rectangular region of interest (ROI) within the image. In Python, this can be achieved using the slicing operator to extract the desired region.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "###    EXERCISE    ###\n",
    "######################\n",
    "\n",
    "# Crop the image such that only the purple white blood cell is visible.\n",
    "# Use the slicing operator to crop the image. \n",
    "\n",
    "# Specify the coordinates of the bounding box\n",
    "xs, ys = 250, 160\n",
    "h, w = 100, 100\n",
    "\n",
    "# Crop the image with the slicing operator\n",
    "img1_crop = ...\n",
    "\n",
    "# Display the image\n",
    "tools.show_image_pair(img1, img1_crop, title1=\"Original\", title2=\"Cropped\", \n",
    "                      shape=None, box_aspect=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Resizing**\n",
    "\n",
    "We can use OpenCV’s [`resize()`](https://docs.opencv.org/4.x/da/d54/group__imgproc__transform.html#ga47a974309e9102f5f08231edc7e7529d) function to resample an image to a specified size. This allows for both downsampling (reducing the image size) and upsampling (increasing the image size). The `interpolation` parameter controls the method used for resizing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "###    EXCERISE    ###\n",
    "######################\n",
    "\n",
    "# Resize the image to half and double its size.\n",
    "img1_half = ...\n",
    "img2_double = ...\n",
    "\n",
    "tools.show_image_chain(images=[img1_half, img1, img2_double], \n",
    "                       titles=[\"Half\", \"Original\", \"Double\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Masking**\n",
    "\n",
    "Masking allows us to isolate a cell from the background, remove artifacts, or mark specific regions as unimportant by setting their pixel values to zero.  \n",
    "\n",
    "A mask is a binary image (with values `True` or `False`). When a mask has the same shape as the input image, it can be used to selectively modify pixel values, enabling targeted processing or segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "###    EXCERISE    ###\n",
    "######################\n",
    "\n",
    "# 1. Create a circular mask with the same size as the image.\n",
    "#    The center and the radius of the circle are provided below.\n",
    "#    You can use cv.circle() or define your own function.\n",
    "# 2. Apply the mask to the image img2.\n",
    "\n",
    "# Center and radius of the circle\n",
    "cx, cy = 220, 300\n",
    "r = 44\n",
    "\n",
    "# We use here a 2D binary mask\n",
    "mask = ...\n",
    "\n",
    "# Apply the mask to the RGB image, set all values to black\n",
    "\n",
    "# Visualize\n",
    "tools.show_image_pair(img2, img2_masked, title1=\"Original\", title2=\"Masked\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Denoising**\n",
    "\n",
    "Denoising is essential for improving image quality, but it requires balancing noise reduction with detail preservation. OpenCV provides several methods for this purpose, including:  \n",
    "\n",
    "- **Gaussian blur**: Smooths the image by averaging pixel values with a weighted kernel.  \n",
    "- **Median blur**: Replaces each pixel value with the median of its neighbors, effective for salt-and-pepper noise.  \n",
    "- **Bilateral filter**: Preserves edges while reducing noise by considering both spatial distance and intensity differences.  \n",
    "\n",
    "\n",
    "Before proceeding, review these OpenCV tutorials on [Smoothing](https://docs.opencv.org/4.x/d4/d13/tutorial_py_filtering.html) and [Image denoising](https://docs.opencv.org/4.x/d5/d69/tutorial_py_non_local_means.html).\n",
    "\n",
    "<!-- - Cropping\n",
    "- Resizing\n",
    "- Masking\n",
    "- Denoising\n",
    "- Enhancing contrast\n",
    "- Sharpening\n",
    "- (Removing artifacts)\n",
    "- Color conversion\n",
    "- Color correction / white balancing\n",
    "- Background removal -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "###    EXCERISE    ###\n",
    "######################\n",
    "\n",
    "# 1. Apply Gaussian blur\n",
    "# 2. Apply median blur\n",
    "# 3. Apply bilateral filter (edge preserving)\n",
    "# 4. Apply a means denoising filter (second link)\n",
    "\n",
    "dst = ...\n",
    "tools.show_image_chain(images=[img1, dst], titles=[\"Original\", \"Denoised\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Sharpening**\n",
    "\n",
    "Sharpening enhances image edges, making details more distinct. Two commonly used methods are **unsharp masking** and **Laplacian filtering**.  \n",
    "\n",
    "### **Unsharp masking:**\n",
    "\n",
    "This method enhances details by subtracting a blurred version of the image from the original:  \n",
    "\n",
    "1. Apply a Gaussian blur to the image.  \n",
    "2. Subtract the blurred image from the original.  \n",
    "3. Add the result back to the original image to enhance edges. \n",
    "\n",
    "### **Laplacian Filter**\n",
    "\n",
    "This method applies a second-order derivative filter to emphasize edges:  \n",
    "\n",
    "- A second-order derivative operator/filter/mask. \n",
    "- Uses specific convolution kernels: [0 1 0; 1 -4 1; 0 1 0] or [-1 -1 -1; -1 8 -1; -1 -1 -1]\n",
    "- Note, the sum of the values of this filter is 0. \n",
    "- Apply using `cv.conv2(img, kernel, \"same\")``\n",
    "\n",
    "Further reading:\n",
    "- [Stackoverflow](https://stackoverflow.com/questions/4993082)\n",
    "- [Geeks for Geeks](https://www.geeksforgeeks.org/image-sharpening-using-laplacian-filter-and-high-boost-filtering-in-matlab/)\n",
    "\n",
    "\n",
    "<!-- - Cropping\n",
    "- Enhancing contrast\n",
    "- (Removing artifacts)\n",
    "- Color conversion\n",
    "- Color correction / white balancing\n",
    "- Background removal -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "###    EXCERISE    ###\n",
    "######################\n",
    "\n",
    "# Implement one of the above methods to sharpen an image.\n",
    "kernel = ...\n",
    "img1_sharp = ...\n",
    "\n",
    "tools.show_image_pair(img1, img1_sharp, \n",
    "                      title1= \"Original\", \n",
    "                      title2=\"Sharpened\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Color / intensity enhancements**\n",
    "\n",
    "In the previous exercise, we explored several histogram-based techniques for enhancing image contrast, including histogram stretching, histogram equalization, and histogram matching.  \n",
    "\n",
    "For specific adjustments, converting to an alternative color space can be beneficial. \n",
    "The **HSV color space** is commonly used to modify saturation and brightness independently.\n",
    "Other color spaces, such as **YCrCb, L\\*a\\*b, and Luv**, separate luminance (intensity) from chrominance (color), allowing for more precise intensity adjustments without affecting color balance.  \n",
    "\n",
    "\n",
    "<!-- - Cropping\n",
    "- Enhancing contrast\n",
    "- (Removing artifacts)\n",
    "- Color conversion\n",
    "- Color correction / white balancing\n",
    "- Background removal -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "###    EXERCISE    ###\n",
    "######################\n",
    "\n",
    "# Using the previous notebook 01-image-processing, \n",
    "# - increase the contrast in the image\n",
    "# - increase the saturation\n",
    "# - try to whiten the background, without losing the cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Background removal**\n",
    "\n",
    "Background removal can be achieved through thresholding (detecting background color), identifying background structure, or applying segmentation techniques to isolate the foreground.  \n",
    "\n",
    "In the next notebook, we may explore segmentation-based background removal. For now, we can experiment with a pre-trained model using the [RemBG package](https://github.com/danielgatis/rembg). This tool leverages a convolutional neural network available on Hugging Face ([see here](https://huggingface.co/spaces/KenjieDec/RemBG)) to automatically remove backgrounds from images.  \n",
    "\n",
    "While the model does not perform well on hematological images, it may work for other types of images. Give it a try and see how it performs on your dataset!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If rembg is not installed yet, uncomment the following line:\n",
    "#%pip install rembg\n",
    "#%pip install onnxruntime\n",
    "from rembg import remove \n",
    "from PIL import Image \n",
    "\n",
    "# # RemBG requires a Pillow image as input. Let's\n",
    "# # convert the NumPy array into a Pillow image.\n",
    "# img_pil = Image.fromarray(img2) \n",
    "# # RemBG does not work for our dataset img1.\n",
    "# img_nobg = remove(img_pil) \n",
    "# tools.show_image_pair(np.asarray(img_pil), np.asarray(img_nobg), background_color=\"pink\")\n",
    "\n",
    "# But it works for other datasets.\n",
    "files = [ \"hematology-blast1.jpg\",\n",
    "          \"hematology-baso2.jpg\",\n",
    "          \"hematology-baso1.jpg\",\n",
    "          \"kingfisher.jpg\", \n",
    "          \"kingfisher-gray.jpg\", \n",
    "          \"histology-image.jpg\", \n",
    "          \"ct-brain-slices.jpg\" ]\n",
    "\n",
    "for f in files:\n",
    "    img_pil = Image.open(\"../data/images/\"+f)\n",
    "    img_nobg = remove(img_pil) \n",
    "    img_nobg.save(\"oink.png\")\n",
    "    tools.show_image_pair(np.asarray(img_pil), np.asarray(img_nobg), \n",
    "                          title1=f, title2=\"No background\",\n",
    "                          background_color=\"pink\")  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-msls-co4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
